<h2 id="publications" style="margin: 2px 0px -15px;">Publications</h2>

<div class="publications">
<ol class="bibliography">

<!-- 
<li>
<div class="pub-row">

  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/principalmanifold.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">arXiv</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2306.06534">Principal and Self-Consistent Positive Semi-Defnite Manifolds</a></div>
    <div class="author"><strong>Hanchao Zhang, Thaddeus Tarpey</strong></div>
    <div class="periodical"><em>arXiv <strong>(arXiv)</strong>, Aug. 2023.</em></div>
    <div class="links">
    <a href="assets/files/single.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Website</a>
      <a href="https://arxiv.org/pdf/2306.06534.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/Hanchao-Zhang/Self-Consistency-Clustering" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">GitHub</a>
      <a href="https://pypi.org/project/KTensors/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Package</a>
      <a href="assets/files/KTensors.bib" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTeX</a>
      <strong><i style="color:#7b5aa6">arXiv.org</i></strong>
    </div>
  </div>
</div>
</li> -->


<li>
<div class="pub-row">

  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/ImgAny.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">arXiv</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2401.17664.pdf">Image Anything: Towards Reasoning-coherent and Training-free Multi-modal Image Generation</a></div>
    <div class="author"><strong>Yuanhuiyi Lyu</strong>, Xu Zheng, Lin Wang</div>
    <div class="periodical"><em>arXiv <strong>(arXiv)</strong>, Feb. 2024.</em></div>
    <div class="links">
    <a href="https://vlislab22.github.io/ImageAnything" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Website</a>
      <a href="https://arxiv.org/pdf/2401.17664.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">

  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/icra.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICRA 2024</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2309.09297.pdf">Chasing Day and Night: Towards Robust and Efficient All-Day Object Detection Guided by an Event Camera</a></div>
    <div class="author">Jiahang Cao, Xu Zheng*, <strong>Yuanhuiyi Lyu*</strong>, Jiaxu Wang, Renjing Xu, Lin Wang</div>
    <div class="periodical"><em>ICRA 2024 <strong>(ICRA 2024)</strong>, Feb. 2024.</em></div>
    <div class="links">
    <a href="https://vlislab22.github.io/EOLO/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Website</a>
      <a href="https://arxiv.org/pdf/2309.09297.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">

  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/univl-dr.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICLR 2023</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://openreview.net/pdf?id=PQOlkgsBsik">Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval</a></div>
    <div class="author"><strong>Zhenghao Liu, Chenyan Xiong, <strong>Yuanhuiyi Lv</strong>, Zhiyuan Liu, Ge Yu</div>
    <div class="periodical"><em>ICLR 2023 <strong>(ICLR 2023)</strong>, 2023.</em></div>
    <div class="links">
    <a href="https://github.com/OpenMatch/UniVL-DR" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://openreview.net/pdf?id=PQOlkgsBsik" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>

<li>
<div class="pub-row">

  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/e-clip.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">arXiv</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2308.03135.pdf">E-CLIP: Towards Label-efficient Event-based Open-world Understanding by CLIP</a></div>
    <div class="author"><strong>Jiazhou Zhou*, Xu Zheng*, <strong>Yuanhuiyi Lyu</strong>, Lin Wang</div>
    <div class="periodical"><em>T-PAMI Under Review <strong>(T-PAMI Under Review)</strong>, 2023.</em></div>
    <div class="links">
    <a href="https://vlislab22.github.io/ECLIP/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Website</a>
      <a href="https://arxiv.org/pdf/2308.03135.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>

<li>
<div class="pub-row">

  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/componerf.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">arXiv</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2303.13843.pdf">CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout</a></div>
    <div class="author">Haotian Bai, <strong>Yuanhuiyi Lyu</strong>, Lutao Jiang, Si Jia Li, Haonan Lu, Xiaodong Lin, Lin Wang</div>
    <div class="periodical"><em>arXiv <strong>(arXiv)</strong>, 2023.</em></div>
    <div class="links">
    <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Website</a>
      <a href="https://arxiv.org/pdf/2303.13843.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>
  </div>
</div>
</li>
  

  
<br>

